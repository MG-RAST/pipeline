#!/usr/bin/env perl 

use strict;
use warnings;
no warnings('once');

use Pipeline;
use Pipeline_Conf;

use Data::Dumper;
use Mail::Mailer;
use Getopt::Long;
use File::Copy;
umask 000;

my $stage_name = "done";
my $stage;
for my $s (@{$Pipeline_Conf::pipeline->{'default'}}){
  $stage = $s if $s->{name} eq $stage_name; 
}
my $stage_id = $stage->{id};
my $revision = "0";
my $version  = $Pipeline_Conf::pipeline_version . "." . $revision;
my $runcmd   = "seq_length_stats.py";
my $mg_email = 'Metagenomics Analysis Server <mg-rast@mcs.anl.gov>';
my $mg_link  = 'http://metagenomics.anl.gov/metagenomics.cgi?page=MetagenomeOverview&metagenome=';

# options
my $job_num  = "";
my $raw_fna  = "";
my $ver_db   = $Pipeline_Conf::ach_annotation_ver;
my $no_stats = 0;
my $no_file  = 0;
my $email    = 0;
my $ver      = "";
my $help     = "";
my $options  = GetOptions ("job=i"     => \$job_num,
			   "raw_fna:s" => \$raw_fna,
			   "ver_db:s"  => \$ver_db,
			   "no_stats!" => \$no_stats,
			   "no_file!"  => \$no_file,
			   "email!"    => \$email,
			   "version!"  => \$ver,
			   "help!"     => \$help,
			 );

if ( $ver ) {
  print STDERR "$stage_name - $version\n";
  exit(0);
} elsif ( $help or (! $job_num) ) {
  print STDERR "Usage: pipeline_$stage_name -j <job number> [-r <raw fasta> --ver_db <db version> --email --no_stats --no_file]\n";
  exit(1);
} 

my $log = Pipeline::logger($job_num);
$log->info("Starting $stage_name on job: $job_num");

# gunzip files
system("compress_job -j $job_num -u") == 0 or fail($log, "uncompress_job: $stage_name failed on job: $job_num");

if ($no_stats) {
  my $result_files = Pipeline::get_result_files();
  push @$result_files, "999.done.domain.stats";
  foreach my $rf (@$result_files) {
    my $file_path = $Pipeline_Conf::global_job_dir."/".$job_num."/".$Pipeline_Conf::results_dir."/".$rf;
    if (! -f $file_path) {
      $log->error("$stage_name failed on job: $job_num, missing file: $file_path");
      exit(1);
    }
  }
  $log->info("Finished $stage_name on job: $job_num, file check only");
  exit(0);
}

# update jobcache stage status
Pipeline::update_stage_info($job_num, $stage_name, "running");

my $job_dir     = $Pipeline_Conf::global_job_dir."/".$job_num;
my $proc_dir    = $job_dir."/proc";
my $run_dir     = $proc_dir."/".$stage_id.".".$stage_name;
my $results_dir = $job_dir."/".$Pipeline_Conf::results_dir;
my $hostname    = `hostname`;
chomp $hostname;

# create directories
if (-d $run_dir) {
  my $t = time;
  $log->info("found $run_dir, moving to $run_dir.$t");
  move($run_dir, $run_dir.".".$t) or fail($log, "$!");
}
mkdir($run_dir) or fail($log, "Could not mkdir: $run_dir, $!");
$log->info("Running on host $hostname, using dir $run_dir");

my $out_file = "$run_dir/$runcmd.out";
my $message  = "$stage_name failed on job: $job_num, see $out_file for details.";

my (@fna_files, @faa_files);
my $result_files = Pipeline::get_result_files();
my $stat_tags    = Pipeline::get_job_stat_tags();

# check if result files exist
foreach my $rf (@$result_files) {
  if ((! -f "$results_dir/$rf") && (! $no_file)) {
    fail($log, "$stage_name failed on job: $job_num, missing file: $results_dir/$rf");
  }
  if ((-s "$results_dir/$rf") && ($rf =~ /\.fna$/)) { push @fna_files, $rf; }
  if ((-s "$results_dir/$rf") && ($rf =~ /\.faa$/)) { push @faa_files, $rf; }
}

# run stats on dna fasta files
foreach my $fna (@fna_files) {
  system(qq(echo "$runcmd on $fna .." >> $out_file));
  if ($fna eq $Pipeline::preprocessed_fasta) {
    system("$runcmd -t fasta -i $results_dir/$fna -o $run_dir/$fna.stats -l $run_dir/$fna.lens -g $run_dir/$fna.gcs >> $out_file 2>&1") == 0 or fail($log, $message);
  } else {
    system("$runcmd -t fasta -i $results_dir/$fna -o $run_dir/$fna.stats >> $out_file 2>&1") == 0 or fail($log, $message);
  }
}
  
# run stats on aa fasta files
foreach my $faa (@faa_files) {
  system(qq(echo "$runcmd on $faa .." >> $out_file));
  system("$runcmd -f -t fasta -i $results_dir/$faa -o $run_dir/$faa.stats >> $out_file 2>&1") == 0 or fail($log, $message);
}

# run stats on cluster files
foreach my $clust (($Pipeline::cluster_map_rna, $Pipeline::cluster_map_aa)) {
  unless (-s "$results_dir/$clust") { next; }
  my $c_num = 0;
  my $c_seq = 0;
  
  open(CLUST, "<$results_dir/$clust") or fail($log, "$stage_name failed on job: $job_num, can not open $results_dir/$clust: $!");
  while (my $line = <CLUST>) {
    chomp $line;
    my @tabs = split(/\t/, $line);
    $c_seq += scalar( split(/,/, $tabs[2]) ) + 1;
    $c_num += 1;
  }
  close CLUST;

  open(CSTAT, ">$run_dir/$clust.stats") or fail($log, "$stage_name failed on job: $job_num, can not open $run_dir/$clust.stats: $!");
  print CSTAT "cluster_count\t$c_num\nclustered_sequence_count\t$c_seq\n";
  close CSTAT;
}

if ($raw_fna && (-s $raw_fna)) {
  my $format    = ($raw_fna =~ /\.(fq|fastq)$/) ? 'fastq' : 'fasta';
  my @raw_tags  = grep { $_ =~ /_raw$/ } @$stat_tags;
  my $raw_size  = -s $raw_fna;
  #my ($raw_md5) = (`md5sum $raw_fna` =~ /^(\S+)/);
  
  system(qq(echo "$runcmd on $raw_fna .." >> $out_file));
  system("$runcmd -t $format -i $raw_fna -o $raw_fna.stats -l $raw_fna.lens -g $raw_fna.gcs >> $out_file 2>&1") == 0 or fail($log, $message);

  load_fasta_stats($job_num, $raw_fna, "$raw_fna.stats", \@raw_tags, "raw");
  Pipeline::set_jobcache_info($job_num, "file_size_raw", $raw_size);
  #Pipeline::set_jobcache_info($job_num, "file_checksum_raw", $raw_md5);
}

# load derep stats
my $derep_rm_file = $run_dir."/".$Pipeline::dereplication_rm_fasta.'.stats';
my $derep_rm_seq  = '0';
if ((-s $derep_rm_file) && (-s $results_dir."/".$Pipeline::dereplication_rm_fasta)) {
    $derep_rm_seq = `grep -w sequence_count $derep_rm_file | cut -f2`;
    chomp $derep_rm_seq;
}
load_stats($job_num, [['sequence_count_dereplication_removed', $derep_rm_seq]]);

# load preprocessed stats
my @pre_rna_tags = grep { $_ =~ /_preprocessed_rna$/ } @$stat_tags;
load_fasta_stats($job_num, $results_dir."/".$Pipeline::preprocessed_rna_fasta, $run_dir."/".$Pipeline::preprocessed_rna_fasta.".stats", \@pre_rna_tags, "preprocessed_rna");
my @pre_tags = grep { $_ =~ /_preprocessed$/ } @$stat_tags;
load_fasta_stats($job_num, $results_dir."/".$Pipeline::preprocessed_fasta, $run_dir."/".$Pipeline::preprocessed_fasta.".stats", \@pre_tags, "preprocessed");

# load processed rna stats
my @proc_rna_tags = grep { $_ =~ /_processed_rna$/ } @$stat_tags;
my $proc_rna_file = (-s $results_dir."/".$Pipeline::processed_fasta_rna_1) ? $Pipeline::processed_fasta_rna_1 : $Pipeline::processed_fasta_rna_2;
load_fasta_stats($job_num, $results_dir."/".$proc_rna_file, $run_dir."/".$proc_rna_file.".stats", \@proc_rna_tags, "processed_rna");
load_fasta_stats($job_num, $results_dir."/".$Pipeline::cluster_map_rna, $run_dir."/".$Pipeline::cluster_map_rna.".stats", \@proc_rna_tags, "processed_rna");
my $rna_pred  = $run_dir."/".$Pipeline::processed_fasta_rna_2.".stats";
my $rna_reads = '0';
if (-s $rna_reads) {
  $rna_reads = `grep -w sequence_count $rna_pred | cut -f2`;
  chomp $rna_reads;
}
load_stats($job_num, [['read_count_processed_rna', $rna_reads]]);

# load processed aa stats
my @proc_aa_tags = grep { $_ =~ /_processed_aa$/ } @$stat_tags;
my $proc_aa_file = (-s $results_dir."/".$Pipeline::processed_fasta_aa_1) ? $Pipeline::processed_fasta_aa_1 : $Pipeline::processed_fasta_aa_2;
load_fasta_stats($job_num, $results_dir."/".$proc_aa_file, $run_dir."/".$proc_aa_file.".stats", \@proc_aa_tags, "processed_aa");
load_fasta_stats($job_num, $results_dir."/".$Pipeline::cluster_map_aa, $run_dir."/".$Pipeline::cluster_map_aa.".stats", \@proc_aa_tags, "processed_aa");
my $aa_pred  = $results_dir."/".$Pipeline::processed_fasta_aa_2;
my $aa_reads = '0';
if (-s $aa_pred) {
  $aa_reads = `grep '^>' $aa_pred | sed 's/_[0-9]*_[0-9]*_[-+]\$//' | sort -u | wc -l`;
  chomp $aa_reads;
}
load_stats($job_num, [['read_count_processed_aa', $aa_reads]]);

load_fasta_stats($job_num, $raw_fna, "$run_dir/700.annotation.sims.stats", [$sim_stats->[0][2], $sim_stats->[1][2], $sim_stats->[2][2]], 0);

# annotated read stat
my $ann_read = '0';
if (-s "$results_dir/900.loadDB.sims.filter.seq") {
  $ann_read = `cut -f1 $results_dir/900.loadDB.sims.filter.seq | sort -u | wc -l`;
  chomp $ann_read;
}
load_stats($job_num, [['read_count_annotated', $ann_read]]);

# calculate taxa abundances
foreach my $taxa (('domain', 'phylum', 'class', 'order', 'family', 'genus', 'species')) {
  my $other = ($taxa eq 'domain') ? 1 : 0;
  my $taxa_stats = Pipeline::get_taxa_abundances($job_num, $taxa, $other, $ver_db);
  if (@$taxa_stats > 0) {
    open(TSTAT, ">$run_dir/$stage_id.$stage_name.$taxa.stats") or fail($log, "$stage_name failed on job: $job_num, can not open $run_dir/$stage_id.$stage_name.$taxa.stats: $!");
    print TSTAT join("\n", map { $_->[0] . "\t" . $_->[1] } @$taxa_stats) . "\n";
    close TSTAT;
  }
}

# calculate ontology abundance
my $ontol_stats = Pipeline::get_ontology_abundances($job_num, $ver_db);
foreach my $ontol (keys %$ontol_stats) {
  if (@{$ontol_stats->{$ontol}} > 0) {
    open(OSTAT, ">$run_dir/$stage_id.$stage_name.$ontol.stats") or fail($log, "$stage_name failed on job: $job_num, can not open $run_dir/$stage_id.$stage_name.$ontol.stats: $!");
    print OSTAT join("\n", map { $_->[0] . "\t" . $_->[1] } @{$ontol_stats->{$ontol}}) . "\n";
    close OSTAT;
  }
}

# calculate rarefaction coordanates
my $rare_stats = Pipeline::get_rarefaction_xy($job_num, $ver_db);
if (@$rare_stats > 0) {
  open(RSTAT, ">$run_dir/$stage_id.$stage_name.rarefaction.stats") or fail($log, "$stage_name failed on job: $job_num, can not open $run_dir/$stage_id.$stage_name.rarefaction.stats: $!");
  print RSTAT join("\n", map { $_->[0] . "\t" . $_->[1] } @$rare_stats) . "\n";
  close RSTAT;
}

# calculate alpha diversity
my $alpha = Pipeline::get_alpha_diversity($job_num, 'shannon', $ver_db);
load_stats($job_num, [['alpha_diversity_shannon', $alpha]]);

# calculate ratio identified reads
my $tag_names = ['sequence_count_sims_rna','cluster_count_processed_rna','clustered_sequence_count_processed_rna','sequence_count_preprocessed_rna',
		 'sequence_count_sims_aa','cluster_count_processed_aa','clustered_sequence_count_processed_aa','sequence_count_preprocessed'];
my $stat_set      = Pipeline::get_job_statistics($job_num, $stat_tags);
my $data_set      = Pipeline::get_job_attributes($job_num, ['sequence_type_guess']);
my $qc_aa_seqs    = exists($stat_set->{sequence_count_preprocessed}) ? $stat_set->{sequence_count_preprocessed} : 0;
my $aa_sims       = exists($stat_set->{sequence_count_sims_aa}) ? $stat_set->{sequence_count_sims_aa} : 0;
my $aa_clusts     = exists($stat_set->{cluster_count_processed_aa}) ? $stat_set->{cluster_count_processed_aa} : 0;
my $aa_clust_seq  = exists($stat_set->{clustered_sequence_count_processed_aa}) ? $stat_set->{clustered_sequence_count_processed_aa} : 0;
my $qc_rna_seqs   = exists($stat_set->{sequence_count_preprocessed_rna}) ? $stat_set->{sequence_count_preprocessed_rna} : 0;
my $rna_sims      = exists($stat_set->{sequence_count_sims_rna}) ? $stat_set->{sequence_count_sims_rna} : 0;
my $rna_clusts    = exists($stat_set->{cluster_count_processed_rna}) ? $stat_set->{cluster_count_processed_rna} : 0;
my $rna_clust_seq = exists($stat_set->{clustered_sequence_count_processed_rna}) ? $stat_set->{clustered_sequence_count_processed_rna} : 0;
my $aa_ratio      = $qc_aa_seqs ? ($aa_sims - $aa_clusts + $aa_clust_seq) / $qc_aa_seqs : 0;
my $rna_ratio     = $qc_rna_seqs ? ($rna_sims - $rna_clusts + $rna_clust_seq) / $qc_rna_seqs : 0;
load_stats($job_num, [['ratio_reads_aa', sprintf("%.3f", $aa_ratio)], ['ratio_reads_rna', sprintf("%.3f", $rna_ratio)]]);

# trust amplicon
my $seq_guess = exists($data_set->{sequence_type_guess}) ? $data_set->{sequence_type_guess} : '';
if ($seq_guess eq 'Amplicon') {
  Pipeline::set_jobcache_info($job_num, 'sequence_type', 'Amplicon');
}
# use ratio for WGS or MT
else {
  my $ratio_guess = ($rna_ratio > 0.25) ? 'MT' : 'WGS';
  Pipeline::set_jobcache_info($job_num, 'sequence_type', $ratio_guess);
}

# gzip files
system("compress_job -j $job_num") == 0 or fail($log, "compress_job: ".$message);

# copy output to somewhere
opendir(RUNDIR, $run_dir) or fail($log, "$stage_name failed on job: $job_num, can not open $run_dir: $!");
my @stats = grep { /\.(stats|lens|gcs)$/ } readdir(RUNDIR);
closedir RUNDIR;
foreach my $sf (@stats) {
  move("$run_dir/$sf", "$results_dir/$sf") or fail($log, "$stage_name failed on job: $job_num, can not move $sf");
  chmod 0666, "$results_dir/$sf";
}

# set job as viewable
Pipeline::set_jobcache_info($job_num, "viewable", 1);

# cleanup AWE
system("rm ".$Pipeline_Conf::AWEdata."/".$job_num);
system("rm -rf ".$Pipeline_Conf::AWEdata."/".$job_num.".results");

# email owner on completion
if ($email) {
  my $mailer   = Mail::Mailer->new();
  my $job_info = Pipeline::get_jobcache_info($job_num);
  my $owner    = Pipeline::get_job_owner($job_num);
  my $name     = $owner->{firstname} . " " . $owner->{lastname};
  my $body_txt = "Dear $name,\n\nThe annotation job that you submitted for '" . $job_info->{name} . "' has completed.\n\n" .
                 "Your job has been assigned MG-RAST metagenome ID " . $job_info->{metagenome_id} .
		 " and can be linked to using:\n$mg_link" . $job_info->{metagenome_id} . "\n\n" .
		 'This is an automated message.  Please contact mg-rast@mcs.anl.gov if you have any questions or concerns.';

  $mailer->open({ From    => $mg_email,
		  To      => "$name <" . $owner->{email} . ">",
		  Subject => "MG-RAST Job Completed",
		})
    or die "Can't open Mail::Mailer: $!\n";
  print $mailer $body_txt;
  $mailer->close();
}

$log->info("Finished $stage_name on job: $job_num");

# update jobcache stage status
Pipeline::update_stage_info($job_num, $stage_name, "completed");

exit(0);

sub fail {
  my ($log, $message) = @_;
  Pipeline::update_stage_info($job_num, $stage_name, "error");
  $log->error($message);
  exit(1);
}

sub load_fasta_stats {
  my ($job_num, $fasta_file, $stats_file, $tags, $step) = @_;

  unless (-s $fasta_file) {
    $log->info("Skipping loading stats for stage '$step', $fasta_file is empty");
    return;
  }
  unless (-s $stats_file) {
    fail($log, "$stage_name failed on job: $job_num, missing file: $stats_file");
  }
  my @stats = `cat $stats_file`;
  chomp @stats;
  if ( $stats[0] =~ /^ERROR/i ) {
    fail($log, "$stage_name failed on job: $job_num, bad stats $stats_file: $stats[0]");
  }

  my @data = ();
  my %tmap = map { $_, 1 } @$tags;
  foreach my $set (@stats) {
    my ($tag, $val) = split(/\t/, $set);
    my $jtag = $step ? $tag.'_'.$step : $tag;
    if (exists $tmap{$jtag}) {
      push @data, [$jtag, $val];
    }
  }
  load_stats($job_num, \@data);
}

sub load_stats {
  my ($job_num, $stats) = @_;
  my $res = Pipeline::set_job_statistics($job_num, $stats);
  unless ($res) {
    fail($log, "$stage_name failed on job: $job_num, loading JobDB stats");
  }  
}
