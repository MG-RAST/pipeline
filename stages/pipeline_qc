#!/usr/bin/env perl 

use strict;
use warnings;
no warnings('once');

use Pipeline;
use Pipeline_Conf;

use Getopt::Long;
use File::Copy;
umask 000;

my $stage_name="qc";
my $stage;
for my $s (@{$Pipeline_Conf::pipeline->{'default'}}) {
  $stage = $s if $s->{name} eq $stage_name; 
}
my $stage_id = $stage->{id} || '075';
my $revision = "0";
my $version  = $Pipeline_Conf::pipeline_version.".".$revision;

# options
my $job_num = "";
my $seqs    = "";
my $name    = "raw";
my $procs   = 4;
my $kmers   = '15,6';
my $ver     = 0;
my $help    = 0;
my $options = GetOptions ("job=i"    => \$job_num,
			  "seqs=s"   => \$seqs,
			  "name:s"   => \$name,
			  "procs:i"  => \$procs,
			  "kmers:s"  => \$kmers,
			  "version!" => \$ver,
			  "help!"    => \$help,
			 );
if ( $ver ) {
  print STDERR "$stage_name - $version - $stage_id\n";
  exit(0);
} elsif ( $help or !($job_num and $seqs) ) {
  print STDERR "Usage: pipeline_$stage_name -j <job number> -s <sequence file> [-k <list of kmer lengths, default '$kmers'> -n <input seqs stage, default '$name'> -p <# processors, default '$procs'>]\n";
  exit(1);
}

my $log = Pipeline::logger($job_num);
$log->info("Starting $stage_name on job: $job_num");

unless (-s $seqs) {
  $log->error("file: $seqs does not exist");
  exit(1);
}

my @kmers = split(/,/, $kmers);
my $bad_kmer = 0;
foreach (@kmers) {
  if ($_ !~ /^\d+$/) { $bad_kmer = 1; }
}
if ((@kmers == 0) || $bad_kmer) {
  $log->error("invalid kmer list: $kmers");
  exit(1);
}

# update jobcache stage status
Pipeline::update_stage_info($job_num, $stage_name, "running");

my $job_dir     = $Pipeline_Conf::global_job_dir."/".$job_num;
my $proc_dir    = $job_dir."/proc";
my $stage_dir   = $proc_dir."/".$stage_id.".".$stage_name;
my $results_dir = $job_dir."/".$Pipeline_Conf::results_dir;
my $run_dir     = $stage_dir;
my $hostname    = `hostname`;
chomp $hostname;

# create directories
if (-d $stage_dir) {
  my $t = time;
  $log->info("found $stage_dir, moving to $stage_dir.$t");
  move($stage_dir, $stage_dir.".".$t) or fail($log, "$!");
}
mkdir($stage_dir) or fail($log, "Could not mkdir: $stage_dir, $!");

# set cluster workspace dir
if (-d $Pipeline_Conf::cluster_workspace) {
  $run_dir = $Pipeline_Conf::cluster_workspace."/$job_num.$stage_id.$stage_name";
  if (-d $run_dir) {
    system("rm -rf $run_dir");
  }
  mkdir($run_dir) or fail($log, "Could not mkdir: $run_dir, $!");
  system("echo $hostname > $stage_dir/hostname");
}
$log->info("Running on host $hostname, using dir $run_dir");

# format
my $format  = '';
my $gzipped = 0;
if ($seqs =~ /^(\S+)\.gz$/) {
  $gzipped = 1;
  $format = ($1 =~ /\.(fq|fastq)$/) ? 'fastq' : 'fasta';
}
else {
  $format = ($seqs =~ /\.(fq|fastq)$/) ? 'fastq' : 'fasta';
}

# files
my $basename = $run_dir."/".$stage_id;
my $log_file = $basename.".qc.out";
my $infile   = $basename.".input.".$format;
my $d_stats  = $basename.".drisee.stats";
my $message  = "$stage_name failed on job: $job_num, see $log_file for details.";

if ($gzipped) {
  system("zcat $seqs > $infile") == 0 or fail($log, "gunzip $seqs: ".$message);
} else {
  system("cp $seqs $infile") == 0 or fail($log, "cp $seqs: ".$message);
}

# create drisee table
system("echo 'running drisee ... ' >> $log_file ");
system("drisee -v -p $procs -t $format -d $run_dir -l $log_file -f $infile $d_stats > $basename.drisee.info 2>&1") == 0 or fail($log, "drisee: ".$message);

# create consensus table
system("echo 'running consensus ... ' >> $log_file ");
system("consensus.py -v -t $format -i $infile -o $basename.consensus.stats >> $log_file 2>&1") == 0 or fail($log, "consensus: ".$message);

# create kmer profile
foreach my $len (@kmers) {
  system("echo 'running kmer-tool for size $len ... ' >> $log_file ");
  system("kmer-tool -l $len -p $procs -i $infile -t $format -o $basename.kmer.$len.stats -f histo -r -d $run_dir >> $log_file 2>&1") == 0 or fail($log, "kmer-tool: ".$message);
}

# load drisee stats
my $d_score = 0;
if (-s $d_stats) {
  $d_score = `head -2 $d_stats | tail -1 | cut -f8`;
  chomp $d_score;
}
my $res = Pipeline::set_job_statistics($job_num, [["drisee_score_$name", sprintf("%.3f", $d_score)]]);
unless ($res) {
  fail($log, "$stage_name failed on job: $job_num, loading drisee_score_$name stat: $d_score");
}  

# copy output to somewhere
opendir(RUNDIR, $run_dir) or fail($log, "$stage_name failed on job: $job_num, can not open $run_dir: $!");
my @stats = grep { /\.(stats|info)$/ } readdir(RUNDIR);
closedir RUNDIR;
foreach my $sf (@stats) {
  move("$run_dir/$sf", "$results_dir/$sf") or fail($log, "$stage_name failed on job: $job_num, can not move $sf");
  chmod 0666, "$results_dir/$sf";
}

# move run_dir to stage_dir if on local
if ($run_dir ne $stage_dir) {
  system("mv $run_dir/*.out $stage_dir/.");
  system("mv $run_dir/*.log $stage_dir/.");
  system("mv $run_dir/*.err $stage_dir/.");
  system("rm -rf $run_dir") == 0 or fail($log, "$stage_name failed on job: $job_num, can not remove $run_dir");
} else {
  my @run_files = `ls $run_dir`;
  chomp @run_files;
  map { system("rm $run_dir/$_") } grep { $_ !~ /\.(out|err|log)$/ } @run_files;
}

$log->info("Finished $stage_name on job: $job_num");

# update jobcache stage status
Pipeline::update_stage_info($job_num, $stage_name, "completed");

exit(0);

sub fail {
  my ($log, $message) = @_;
  Pipeline::update_stage_info($job_num, $stage_name, "error");
  $log->error($message);
  if ($run_dir ne $stage_dir) {
    system("mv $run_dir/* $stage_dir/.");
    system("rmdir $run_dir");
  }
  exit(1);
}
